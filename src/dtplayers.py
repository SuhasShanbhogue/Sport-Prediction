# -*- coding: utf-8 -*-
"""DTplayers.ipynb

Automatically generated by Colaboratory.

Original file is located at
		https://colab.research.google.com/drive/1tid1LUg0cz-ZtGNhG7Lo8HQJIWUGdEeh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.decomposition import PCA

p_2011 = pd.read_csv("../Data/Players_final_2011.csv")
p_2012 = pd.read_csv("../Data/Players_final_2012.csv")
p_2013 = pd.read_csv("../Data/Players_final_2013.csv")
p_2014 = pd.read_csv("../Data/Players_final_2014.csv")
p_2015 = pd.read_csv("../Data/Players_final_2015.csv")

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
 
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import roc_curve
from matplotlib import pyplot
import seaborn as sn
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import confusion_matrix

%matplotlib inline

def metrics(y_true,y_preds,y_probs):
	roc = roc_auc_score(y_true,y_probs)
	print("The ROC AUC Score is: {}".format(roc.round(5)))
	f1score = f1_score(y_true, y_preds)
	print("The F1 score is: {}".format(f1score.round(5)))
	cf = confusion_matrix(y_true,y_preds)
	print("The Confusion Matrix is:")
	# plot_confusion_matrix(clf, X_test, y_test,
	#                       cmap=plt.cm.binary)
	cm =confusion_matrix(y_test, y_preds)  
	index = [1, 0]  
	columns = [1, 0]  
	cm_df = pd.DataFrame(cm,columns,index)                      
	plt.figure(figsize=(10,6))  
	# sns.heatmap(cm_df, annot=True, cmap=plt.cm.binary)
	# plt.show()

def metrics_combined(comb_y_true,comb_y_pred,comb_y_probs):
	roc =0
	f1score =0
	roc_l=[]
	f1_score_l=[]
	cf_total=0
	for i in range(4):
		roc += roc_auc_score(comb_y_true[i],comb_y_probs[i])
		roc_l.append(roc_auc_score(comb_y_true[i],comb_y_probs[i]))
		f1score += f1_score(comb_y_true[i],comb_y_pred[i])
		f1_score_l.append(f1_score(comb_y_true[i],comb_y_pred[i]))
		cf = confusion_matrix(comb_y_true[i],comb_y_pred[i])
		cf_total += cf
	
	print("Mean ROC score:{}".format((roc/4).round(5)))
	print("Mean F1 score{}".format((f1score/4).round(5)))
	# cm =confusion_matrix(y_test, y_preds)  
	index = [1, 0]  
	columns = [1, 0]  
	cm_df = pd.DataFrame(cf_total,columns,index)                      
	plt.figure(figsize=(10,6))  
	sns.set(font_scale=1.2)
	st1 = sns.heatmap(cm_df, annot=True, cmap=plt.cm.binary)
	plt.show()
	fig = st1.get_figure()
	fig.savefig("../content/cfmat.png") 
	x = ["2012", "2013", "2014", "2015"] 
	plt.plot(x,roc_l,label='ROC', linestyle = '--', color = 'black')
	plt.plot(x,f1_score_l,label='F1_score', linestyle = '-', color = 'gray')
	plt.legend()
	plt.ylabel('ROC/F1-score')
	plt.savefig("../content/Split VS ROC-F1-score.png")
	plt.show()

l = [p_2011,
		 p_2012,
		 p_2013,
		 p_2014,
		 p_2015]
Wi = 'Winner'
rocs = []
average = 0
comb_y_true = []
comb_y_preds = []
comb_y_probs = []
for i in range(4):
	frames = []
	for j in range(i+1):
			frames.append(l[j])
	# print("\n")
	train = pd.concat(frames)
	X_train = train.drop([Wi], axis = 1)
	scaler = StandardScaler()
	scaler.fit(X_train)  
	X_train = scaler.transform(X_train)
	y_train = train[Wi]
	clf = DecisionTreeClassifier(random_state=0, criterion="entropy", ccp_alpha=0.06,
															 class_weight='balanced',
															 splitter = "random")
	clf.fit(X_train, y_train)
	test = l[i+1]
	X_test = test.drop([Wi], axis = 1)
	X_test = scaler.transform(X_test)
	y_test = test[Wi]
	y_preds = clf.predict(X_test)
	y_probs = clf.predict_proba(X_test)[:,1]
	comb_y_true.append(y_test)
	comb_y_preds.append(y_preds)
	comb_y_probs.append(y_probs)
	metrics(y_test, y_preds, y_probs)
metrics_combined(comb_y_true, comb_y_preds, comb_y_probs)